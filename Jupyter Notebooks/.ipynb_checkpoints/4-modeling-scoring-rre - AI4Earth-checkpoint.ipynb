{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# In this module...\n",
    "\n",
    "- We will learn how to train and test models with the `RevoScaleR` package.\n",
    "- Use your knowledge of data manipulation to create **train** and **test** sets.\n",
    "- Use the modeling functions in `RevoScaleR` to train a model.\n",
    "- Use the `rxPredict` function to test/score a model.\n",
    "- We will see how you can score models on a variety of data sources.\n",
    "- Use a functional methodology, i.e., we will create functions to automate the modeling, validation, and scoring process.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Understanding of `rxDataStep` and `xdfs`\n",
    "- Familiarity with `RevoScaleR` modeling and datastep functions: `rxLinMod`, `rxGlm`, `rxLogit`, `rxDTree`, `rxDForest`, `rxSplit`, and `rxPredict`\n",
    "- Understand how to write functions in R\n",
    "- Access to at least one interesting dataset\n",
    "\n",
    "## Typical Lifecycle\n",
    "\n",
    "![](http://oliviak.blob.core.windows.net/blog/ML%20series/6%203%20mkt%201.png)\n",
    "\n",
    "### For this module we will...\n",
    "\n",
    "- Start with a data set\n",
    "- Split the data into separate training and validation/evaluation data sets\n",
    "- Use the `ScaleR` modeling functions on the train set to estimate your model\n",
    "- Use `rxPredict` to score then evaluate the model you built.\n",
    "\n",
    "## Mortgage Dataset\n",
    "\n",
    "- We will work with a mortgage dataset, which contains mortgage and credit profiles for various mortgage holders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "create_path_to_mortgages, message = FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 1\n",
    "#----------------------\n",
    "\n",
    "getwd()\n",
    "setwd(\"C:\\\\dsvm\\\\\")\n",
    "\n",
    "bradypus_xdf <- RxXdfData(\"Bradypus_Species_Modeling_Training_Data.xdf\")\n",
    "rxGetInfo(bradypus_xdf, getVarInfo = TRUE, numRows = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transform Default to Categorical\n",
    "\n",
    "- We might be interested in estimating a classification model for predicting defaults based on credit attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "add_default_flag",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 2\n",
    "#----------------------\n",
    "\n",
    "rxDataStep(inData = bradypus_xdf\n",
    "           ,outFile = bradypus_xdf\n",
    "           ,overwrite = TRUE\n",
    "           ,transforms = list(default_flag = factor(ifelse(default == 1,\n",
    "                                                          \"default\",\n",
    "                                                          \"current\"))\n",
    "                             )\n",
    "           )\n",
    "\n",
    "rxGetInfo(bradypus_xdf, numRows = 3, getVarInfo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Modeling\n",
    "## Generating Training and Test Sets\n",
    "\n",
    "- The first step to estimating a model is having a tidy training dataset.\n",
    "- We will work with the mortgage data and use `rxSplit` to create partitions.\n",
    "- `rxSplit` splits an input `.xdf` into multiple `.xdfs`, similar in spirit to the `split` function in base R\n",
    "- output is a list\n",
    "- First step is to create a split variable\n",
    "- We will randomly partition the data into a train and test sample, with 75% in the former, and 25% in the latter\n",
    "\n",
    "## Partition Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "partition_function",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 3\n",
    "#----------------------\n",
    "#build a function that creates data partitions for training and testing a model\n",
    "\n",
    "create_partition <- function(xdf , partition_size  , ...) \n",
    "                    {\n",
    "                      rxDataStep(inData = xdf\n",
    "                                 ,outFile = xdf\n",
    "                                 ,transformObjects = list(splitperc = partition_size)\n",
    "                                 ,overwrite = TRUE, ...)\n",
    "    \n",
    "                      transforms = list(trainvalidate = factor(ifelse(rbinom(.rxNumRows,size = 1, prob = splitperc)\n",
    "                                                                   , \"train\"\n",
    "                                                                   , \"validate\"\n",
    "                                                                      )\n",
    "                                                                )\n",
    "                                       )\n",
    "\n",
    "                      splitDS <- rxSplit(inData = xdf\n",
    "                                         ,outFileSuffixes = c(\"train\", \"validate\")\n",
    "                                         ,splitByFactor = \"trainvalidate\"\n",
    "                                         ,overwrite = TRUE)\n",
    "\n",
    "                      return(splitDS)\n",
    "\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Minimizing IO\n",
    "### Transforms in rxSplit\n",
    "\n",
    "While the above example does what we want it to do, it's not very efficient. It requires two passes over the data, first to add the `trainvalidate` column, and then another to split it into train and validate sets. We could do all of that in a single step if we pass the transforms directly to `rxSplit`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "split_transforms",
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 4\n",
    "#----------------------\n",
    "\n",
    "create_partition <- function(xdf ,\n",
    "                             partition_size , ...) \n",
    "                    {\n",
    "\n",
    "                      splitDS <- rxSplit(inData = xdf\n",
    "                                 , transformObjects = list(splitperc = partition_size)\n",
    "                                 , transforms = list(\n",
    "                                       trainvalidate = factor(ifelse(rbinom(.rxNumRows, size = 1, prob = splitperc)\n",
    "                                                            , \"train\"\n",
    "                                                            , \"validate\"\n",
    "                                                                    )\n",
    "                                                               )\n",
    "                                                    )\n",
    "                                 ,outFileSuffixes = c(\"train\", \"validate\")\n",
    "                                 ,splitByFactor = \"trainvalidate\"\n",
    "                                 ,overwrite=TRUE)\n",
    "\n",
    "                      return(splitDS)\n",
    "\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Generating Training and Test Sets\n",
    "### List of xdfs\n",
    "\n",
    "- The `create_partition` function will output a list `xdfs`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "split_mortgages_data",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 5\n",
    "#----------------------\n",
    "# use the create_partition function you just created\n",
    "\n",
    "mort_split <- create_partition( xdf = mort_xdf\n",
    "                               ,partition_size = 0.70\n",
    "                               ,reportProgress = 0)\n",
    "\n",
    "names(mort_split) <- c(\"train\", \"validate\")\n",
    "\n",
    "paste0(\"The class of mort_split is:  \" , class(mort_split))\n",
    "\n",
    "#you can now use lapply to apply the rxGetInfo function to the list of xdf data files\n",
    "lapply(mort_split, rxGetInfo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Build Your Model\n",
    "### Model Formula\n",
    "\n",
    "- Once you have a training dataset, the most appropriate next step is to estimate your model\n",
    "- `RevoScaleR` provides a plethora of modeling functions to choose from: decision trees, ensemble trees, linear models, and generalized linear models\n",
    "- All take a formula as the first object in their call\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "model_function",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 6\n",
    "#----------------------\n",
    "\n",
    "make_form <- function(xdf = mort_xdf,\n",
    "                      resp_var = \"default_flag\",\n",
    "                      vars_to_skip = c(\"default\", \"trainvalidate\")) {\n",
    "\n",
    "              library(stringr)\n",
    "\n",
    "              non_incl <- paste(vars_to_skip, collapse = \"|\")\n",
    "\n",
    "              x_names <- names(xdf)\n",
    "\n",
    "              features <- x_names[!str_detect(x_names, resp_var)]\n",
    "              features <- features[!str_detect(features, non_incl)]\n",
    "\n",
    "              form <- as.formula(paste(resp_var, paste0(features, collapse = \" + \"),\n",
    "                                       sep  = \" ~ \"))\n",
    "\n",
    "              return(form)\n",
    "}\n",
    "\n",
    "## Turns out, RevoScaleR already has a function for this\n",
    "formula(mort_xdf, depVar = \"default_flag\", varsToDrop = c(\"default\", \"trainvalidate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Build Your Model\n",
    "### Modeling Function\n",
    "\n",
    "- Use the `make_form` function inside your favorite `rx` modeling function\n",
    "- Default value will be a logistic regression, but can update the `model` parameter to any `rx` modeling function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "train_function",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 7\n",
    "#----------------------\n",
    "\n",
    "\n",
    "#Create a model estimation function\n",
    "estimate_model <- function(xdf_data = mort_split[[\"train\"]]\n",
    "                           ,form = make_form(xdf_data)\n",
    "                           ,model = rxLogit, ...) \n",
    "                  {\n",
    "\n",
    "                   rx_model <- model(form, data = xdf_data, ...)\n",
    "\n",
    "                   return(rx_model)\n",
    "\n",
    "\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Build Your Model\n",
    "### Train Your Model with Our Modeling Function\n",
    "\n",
    "- Let us now train our logistic regression model for defaults using the `estimate_model` function from the last slide\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "train_models, message = FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 8\n",
    "#----------------------\n",
    "\n",
    "default_model_logit <- estimate_model(xdf_data=mort_split$train\n",
    "                                      ,model = rxLogit\n",
    "                                      ,reportProgress = 0)\n",
    "summary(default_model_logit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Building Additional Models\n",
    "\n",
    "- We can change the parameters of the `estimate_model` function to create a different model relatively quickly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "train_tree",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 9\n",
    "#----------------------\n",
    "#use the estimate_model function to\n",
    "default_model_tree <- estimate_model(mort_split$train\n",
    "                                     ,model = rxDTree\n",
    "                                     ,minBucket = 10\n",
    "                                     ,reportProgress = 0)\n",
    "#to see the output tree logic\n",
    "default_model_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Validation\n",
    "## How Does it Perform on Unseen Data\n",
    "### rxPredict for Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "remove_any_older_xdf, echo = FALSE, message = F",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 10\n",
    "#----------------------\n",
    "\n",
    "options(stringsAsFactors = TRUE)\n",
    "if(file.exists(\"scored.xdf\")) file.remove('scored.xdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Now that we have built our model, our next step is to see how it performs on data it has yet to see\n",
    "- We can use the `rxPredict` function to score/validate our results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "test_logistic_model",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 11\n",
    "#----------------------\n",
    "\n",
    "default_logit_scored <- rxPredict(default_model_logit\n",
    "                                  , mort_split$validate\n",
    "                                  , \"scored.xdf\"\n",
    "                                  , writeModelVars = TRUE\n",
    "                                  , extraVarsToWrite = \"default\"\n",
    "                                  , predVarNames = c(\"pred_logit_default\")\n",
    "                                  ,reportProgress=0)\n",
    "                                 \n",
    "rxGetInfo(default_logit_scored, numRows = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Visualize Model Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 12\n",
    "#----------------------\n",
    "#Get summary statistics and look at distribution of the scored probabilities\n",
    "\n",
    "rxSummary(pred_logit_default~default_flag,\n",
    "          , data=default_logit_scored\n",
    "          , summaryStats = c(\"Mean\", \"StdDev\", \"ValidObs\", \"MissingObs\")\n",
    "          , report=0)\n",
    "\n",
    "\n",
    "\n",
    "rxHistogram(~pred_logit_default|default_flag\n",
    "            , data=default_logit_scored\n",
    "            , histType=\"Percent\"\n",
    "            , fillColor=\"#0072c8\"\n",
    "            , main=\"Examing scored probabilities by actual default\"\n",
    "            , xTitle=\"Predicted Probability\"\n",
    "            , report=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 13\n",
    "#----------------------\n",
    "# Can convert to dataframe and use Open R functions\n",
    "\n",
    "graph_data<-rxDataStep(inData=default_logit_scored\n",
    "                      ,reportProgress=0)\n",
    "\n",
    "cdf_current <- ecdf(graph_data$pred_logit_default[graph_data$default_flag==\"current\"])  \n",
    "plot(cdf_current, xlab=\"Probability of Default\"\n",
    "     , ylab=\"Cummulative Percent\", \n",
    "     , main=\"Loan Default Cummulative Probability Distribution\", cex.main=1, font=1\n",
    "     , sub=\"Logistic Regression Model\"\n",
    "     , col=\"darkred\")\n",
    "abline(v=0.030, lty=3, col=\"forestgreen\")\n",
    "\n",
    "cdf_default <- ecdf(graph_data$pred_logit_default[graph_data$default_flag==\"default\"])  \n",
    "plot(cdf_default\n",
    "     , lty=2, pch=16, cex=.6\n",
    "     , col=\"blue\"\n",
    "     , add=TRUE )\n",
    "legend(\"right\",legend=c(\"Current\", \"Defaulted\"),\n",
    "      col=c(\"darkred\", \"blue\"), lty=c(1,2), cex=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 14\n",
    "#----------------------\n",
    "\n",
    "#plot ROC curve\n",
    "plot(rxRoc(actualVarName = \"default\"\n",
    "          , predVarNames =\"pred_logit_default\"\n",
    "          , data = default_logit_scored)\n",
    "          , main=\"ROC Curve - Logistic Regression Model\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testing a Second Model\n",
    "### rxPredict for Decision Tree\n",
    "\n",
    "- We saw how easy it was to train on different in the previous sections\n",
    "- Similary simple to test different models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "test_d_tree_model",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 15\n",
    "#----------------------\n",
    "\n",
    "default_tree_scored <- rxPredict(default_model_tree\n",
    "                                 , mort_split$validate\n",
    "                                 , \"scored.xdf\"\n",
    "                                 , writeModelVars = TRUE\n",
    "                                 , predVarNames = c(\"pred_tree_current\",\n",
    "                                                  \"pred_tree_default\")\n",
    "                                 , reportProgress=0)\n",
    "                                 \n",
    "\n",
    "rxGetInfo(data=default_tree_scored, getVarInfo=TRUE, numRows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualize Multiple ROCs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "roc_multiple",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 16\n",
    "#----------------------\n",
    "\n",
    "rxRocCurve(\"default\"\n",
    "          , c(\"pred_logit_default\", \"pred_tree_default\")\n",
    "          , data = default_tree_scored\n",
    "          , main=\"ROC Comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lab - Estimate Other Models Using the Functions Above\n",
    "\n",
    "## Ensemble Tree Algorithms\n",
    "\n",
    "Two of the most predictive algorithms in the `RevoScaleR` package are the `rxBTrees` and `rxDForest` algorithms, for gradient boosted decision trees and random forests, respectively.\n",
    "\n",
    "Use the above functions and estimate a model for each of those algorithms, and add them to the `default_tree_scored` dataset to visualize ROC and AUC metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "eval = FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 17\n",
    "#----------------------\n",
    "\n",
    "## Starter code\n",
    "\n",
    "default_model_forest <- estimate_model(mort_split$train\n",
    "                                       ,model = rxDForest\n",
    "                                       ,nTree = 100\n",
    "                                       ,importance = TRUE\n",
    "                                       ,### any other args?\n",
    "                                       , reportProgress = 0)\n",
    "\n",
    "default_forest_scored <- rxPredict(default_model_forest\n",
    "                                    ,mort_split$validate\n",
    "                                    , \"scored.xdf\"\n",
    "                                    , type = 'prob'\n",
    "                                    , predVarNames = c(\"pred_forest_current\", \"pred_forest_default\", \"pred_default\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 18\n",
    "#----------------------\n",
    "\n",
    "## same for rxBTrees\n",
    "\n",
    "default_model_gbm <- estimate_model(mort_split$train\n",
    "                                    ,model = rxBTrees\n",
    "                                    ,nTree = 100\n",
    "                                    ,### any other args?\n",
    "                                    ,reportProgress = 0)\n",
    "\n",
    "default_gbm_scored <- rxPredict(default_model_gbm\n",
    "                                , mort_split$validate\n",
    "                                , \"scored.xdf\"\n",
    "                                , predVarNames = c(\"pred_gbm_default\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "fig.width=11, fig.height = 8",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 19\n",
    "#----------------------\n",
    "\n",
    " rxRocCurve(actualVarName = \"default\",\n",
    "            predVarNames = c(\"pred_tree_default\"\n",
    "                            , \"pred_logit_default\"\n",
    "                            , \"pred_forest_default\"\n",
    "                            , \"pred_gbm_default\")\n",
    "            ,data = 'scored.xdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Deploy (publish) your model to Azure ML as a Web Service\n",
    " You'll need the AzureML package as well as an Azure ML account.\n",
    "### Log into your [Azure ML account](https://studio.azureml.net) and copy your _workspace id_ and _primary authorization token_ under Settings.\n",
    "\n",
    "The general steps are...\n",
    "\n",
    "-  Convert the ScaleR model to it's open source R equivalent\n",
    "-  define the format of the new data to be scored\n",
    "-  create a scoring function to publish\n",
    "-  get AzureML workspace ID and token authorization key\n",
    "-  publish the model\n",
    "\n",
    " More information on ScaleR Functions and converting models can be found at:\n",
    "[RevoScaleR Functions](https://msdn.microsoft.com/en-us/microsoft-r/scaler/scaler).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 20\n",
    "#----------------------\n",
    "\n",
    "library(AzureML)\n",
    "library(gbm)\n",
    "\n",
    "#Convert RevoScaleR model to Open R equivalent\n",
    "gbm_publish<-as.gbm(default_model_gbm)\n",
    "\n",
    "#convert xdf to df to test model conversion and scoring\n",
    "newdata_df<-rxDataStep(inData=mort_split$validate, \n",
    "                       varsToKeep=c(\"creditScore\",\"houseAge\",\"yearsEmploy\",\"ccDebt\" ,\"year\"))\n",
    "\n",
    "ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 21\n",
    "#----------------------\n",
    "\n",
    "#Test scoring function\n",
    "testpredict<-predict(gbm_publish, newdata_df, n.trees=10, type=\"response\")\n",
    "head(testpredict, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "_Note_: when creating the scoring function, you have to include any required packages.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 22\n",
    "#----------------------\n",
    "\n",
    "#--Create schema for new data being scored\n",
    "inputscheme<-newdata_df[1,]\n",
    "\n",
    "#--Create scoring function \n",
    "\n",
    "deploygbm<-function (newdata)\n",
    "{  \n",
    "  require(gbm)\n",
    "  predict(gbm_publish, newdata, n.trees=10, type=\"response\")\n",
    " \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Define AzureML workspace which will house the web service and publish your model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 23\n",
    "#----------------------\n",
    "\n",
    "#--Set workspace parameters\n",
    "\n",
    "wsID= 'YOUR AZURE ML Workspace ID here'\n",
    "wsAuth = 'YOUR AZURE ML Primary Authorization Token here'\n",
    "\n",
    "wsDefinition=workspace(wsID, wsAuth)\n",
    "\n",
    "#--Publish web service to AzureML\n",
    "DeployGBM_demo <-publishWebService(wsDefinition\n",
    "                                    ,fun=deploygbm\n",
    "                                    ,name=\"DeployGBM_demo\"\n",
    "                                    ,inputSchema =inputscheme)\n",
    "ls() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# More Advanced Topics\n",
    "\n",
    "## Scoring on Non-XDF Data Sources\n",
    "### Using a CSV as a Data Source\n",
    "\n",
    "- The previous slides focused on using xdf data sources\n",
    "- Most of the `rx` functions will work on non-xdf data sources\n",
    "- For training, which is often an iterative process, it is recommended to use xdfs\n",
    "- For scoring/testing, which requires just one pass through the data, feel free to use raw data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "csv_copy",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 24\n",
    "#----------------------\n",
    "\n",
    "csv_path <- paste(rxGetOption(\"sampleDataDir\")\n",
    "                   , \"mortDefaultSmall2009.csv\"\n",
    "                   , sep = \"/\")\n",
    "\n",
    "file.copy(csv_path, \"mortDefaultSmall2009.csv\", overwrite = TRUE)\n",
    "\n",
    "mort_csv <- RxTextData(\"mortDefaultSmall2009.csv\")\n",
    "\n",
    "ls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Regression Tree\n",
    "\n",
    "- For a slightly different model, we will estimate a regression tree.\n",
    "- Just change the parameters in the `estimate_model` function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "reg_tree",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 25\n",
    "#----------------------\n",
    "\n",
    "tree_model_ccdebt <- estimate_model(xdf_data = mort_split$train\n",
    "                                   , form = make_form(xdf=mort_split$train,\n",
    "                                                     resp_var=\"ccDebt\",\n",
    "                                                     vars_to_skip = c(\"default_flag\",\n",
    "                                                                      \"trainvalidate\"))\n",
    "                                   , model = rxDTree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Test on CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "message = FALSE, warnings = FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 26\n",
    "#----------------------\n",
    "#clean out predictions file in case\n",
    "\n",
    "if (file.exists(\"mort2009predictions.xdf\")) file.remove(\"mort2009predictions.xdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "test_csv",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 27\n",
    "#----------------------\n",
    "\n",
    "rxPredict(tree_model_ccdebt\n",
    "          ,data = mort_csv\n",
    "          ,outData = \"mort2009predictions.xdf\"\n",
    "          ,writeModelVars = TRUE)\n",
    "\n",
    "mort_2009_pred <- RxXdfData(\"mort2009predictions.xdf\")\n",
    "\n",
    "rxGetInfo(mort_2009_pred, numRows = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Multiclass Classification\n",
    "## Convert Year to Factor\n",
    "\n",
    "- We have seen how to estimate a binary classification model and a regression tree\n",
    "- How would we estimate a multiclass classification model?\n",
    "- Let's try to predict mortgage origination based on other variables\n",
    "- Use `rxFactors` to convert *year* to a _factor_ variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convert Year to Factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "create_year_factor",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 28\n",
    "#----------------------\n",
    "\n",
    "mort_xdf_factor <- rxFactors(inData = mort_xdf\n",
    "                             ,factorInfo = c(\"year\")\n",
    "                             ,outFile = \"mort_year.xdf\"\n",
    "                             ,overwrite = TRUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "view_multiclass",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 29\n",
    "#----------------------\n",
    "\n",
    "rxGetInfo(mort_xdf_factor, getVarInfo = TRUE, numRows = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Estimate Multiclass Classification\n",
    "\n",
    "- You know the drill! Change the parameters in `estimate_model`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "multiclass_tree, eval = FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 30\n",
    "#----------------------\n",
    "\n",
    "tree_multiclass_year <- estimate_model(xdf_data = mort_xdf_factor\n",
    "                                  ,  form = make_form(xdf =mort_xdf_factor,\n",
    "                                                     resp_var=\"year\",\n",
    "                                                     vars_to_skip = c(\"default\",\n",
    "                                                                      \"trainvalidate\"))\n",
    "                                   , model = rxDTree\n",
    "                                   ,reportProgress=0)\n",
    "\n",
    "#see the model\n",
    "tree_multiclass_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Predict Multiclass Classification\n",
    "\n",
    "- Score the results\n",
    "- View the results\n",
    "- Predicted/scored column for each level (year) of the response\n",
    "- See that the probabilities sum up to one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "multiclass_prediction, eval = FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Code cell 31\n",
    "#----------------------\n",
    "\n",
    "multiclass_preds <- rxPredict(tree_multiclass_year\n",
    "                              ,data = mort_xdf_factor\n",
    "                              ,writeModelVars = TRUE\n",
    "                              ,outData = \"multi.xdf\"\n",
    "                              ,overwrite = TRUE)\n",
    "\n",
    "\n",
    "rxGetInfo(multiclass_preds, numRows = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Conclusion\n",
    "### Thanks for Attending!\n",
    "\n",
    "- Any questions?\n",
    "- Try different models!\n",
    "- Try modeling with `rxDForest`, `rxBTrees`: have significantly higher predictive accuracy, somewhat less interpretability\n"
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Ali Zaidi",
   "date": "`r format(Sys.Date(), \"%B %d, %Y\")`",
   "output": {
    "html_document": {
     "keep_md": true,
     "toc": true,
     "toc_float": true
    },
    "html_notebook": {
     "toc": true,
     "toc_float": true
    },
    "ioslides_presentation": {
     "logo": "images/clark-logo.png",
     "smaller": true,
     "widescreen": true
    },
    "revealjs::revealjs_presentation": {
     "center": true,
     "css": "slides.css",
     "incremental": true,
     "previewLinks": true,
     "reveal_plugins": [
      "zoom",
      "notes"
     ],
     "self_contained": false,
     "slideNumber": true,
     "theme": "night",
     "viewDistance": 3
    }
   },
   "title": "Modeling and Scoring with RevoScaleR"
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
